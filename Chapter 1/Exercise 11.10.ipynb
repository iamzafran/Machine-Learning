{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def dnn(inputs, n_hidden_layers=5, n_neurons=100,activation=tf.nn.elu, initializer=he_init, name=None):\n",
    "    \n",
    "    with tf.variable_scope('dnn'):\n",
    "        for layer in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, activation=activation, kernel_initializer=initializer, name=name+\"hidden%d\"%(layer+1))\n",
    "        \n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, 2, n_inputs), name='X')\n",
    "X1, X2 = tf.unstack(X, axis=1)\n",
    "y = tf.placeholder(tf.int32, shape=[None, 1])\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "dnn1 = dnn(X1, name='DNN_A')\n",
    "dnn2 = dnn(X2, name='DNN_B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn_outputs = tf.concat([dnn1, dnn2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = tf.layers.dense(dnn_outputs, units=10, activation=tf.nn.elu, kernel_initializer=he_init)\n",
    "logits = tf.layers.dense(hidden, units=1, kernel_initializer=he_init)\n",
    "y_proba = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.cast(tf.greater_equal(logits, 0), tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_as_float = tf.cast(y, tf.float32)\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_as_float, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.95\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_correct = tf.equal(y_pred, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(y_pred_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1 = mnist.train.images\n",
    "y_train1 = mnist.train.labels\n",
    "\n",
    "X_train2 = mnist.validation.images\n",
    "y_train2 = mnist.validation.labels\n",
    "\n",
    "X_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(images, labels, batch_size):\n",
    "    size1 = batch_size // 2\n",
    "    size2 = batch_size - size1\n",
    "    \n",
    "    if size1 != size2 and np.random.rand() > 0.5:\n",
    "        size1, size2 = size2, size1\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    while len(X) < size1:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if rnd_idx1 != rnd_idx2 and labels[rnd_idx1] == labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([1])\n",
    "    while len(X) < batch_size:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if labels[rnd_idx1] != labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([0])\n",
    "    rnd_indices = np.random.permutation(batch_size)\n",
    "    return np.array(X)[rnd_indices], np.array(y)[rnd_indices]\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANMAAAGfCAYAAADF6ud6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCJOJyAiTicgIk4nICJOJyAiTicjI/wHHQrGphhfTyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2bd2bffeac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(3, 3 * batch_size))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_batch[:,0].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_batch[:,1].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test1, y_test1 = generate_batch(X_test, y_test, batch_size=len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train loss: 0.5338755\n",
      "0 Test accuracy 0.7408\n",
      "1 Train loss: 0.39046204\n",
      "2 Train loss: 0.31425804\n",
      "3 Train loss: 0.28741845\n",
      "4 Train loss: 0.24531163\n",
      "5 Train loss: 0.25674966\n",
      "5 Test accuracy 0.9047\n",
      "6 Train loss: 0.21340445\n",
      "7 Train loss: 0.18449663\n",
      "8 Train loss: 0.20152755\n",
      "9 Train loss: 0.14857554\n",
      "10 Train loss: 0.12550351\n",
      "10 Test accuracy 0.94\n",
      "11 Train loss: 0.1592762\n",
      "12 Train loss: 0.1570555\n",
      "13 Train loss: 0.13846368\n",
      "14 Train loss: 0.16024707\n",
      "15 Train loss: 0.11052166\n",
      "15 Test accuracy 0.9541\n",
      "16 Train loss: 0.102970876\n",
      "17 Train loss: 0.10418608\n",
      "18 Train loss: 0.119449675\n",
      "19 Train loss: 0.12207922\n",
      "20 Train loss: 0.10479155\n",
      "20 Test accuracy 0.9565\n",
      "21 Train loss: 0.091848664\n",
      "22 Train loss: 0.09217306\n",
      "23 Train loss: 0.049737953\n",
      "24 Train loss: 0.07485326\n",
      "25 Train loss: 0.0739202\n",
      "25 Test accuracy 0.965\n",
      "26 Train loss: 0.082870595\n",
      "27 Train loss: 0.062747\n",
      "28 Train loss: 0.07317226\n",
      "29 Train loss: 0.08445044\n",
      "30 Train loss: 0.090127766\n",
      "30 Test accuracy 0.9639\n",
      "31 Train loss: 0.04166068\n",
      "32 Train loss: 0.07437489\n",
      "33 Train loss: 0.06800273\n",
      "34 Train loss: 0.045411207\n",
      "35 Train loss: 0.06780513\n",
      "35 Test accuracy 0.9709\n",
      "36 Train loss: 0.049259707\n",
      "37 Train loss: 0.09361489\n",
      "38 Train loss: 0.07276326\n",
      "39 Train loss: 0.04074905\n",
      "40 Train loss: 0.053407826\n",
      "40 Test accuracy 0.9692\n",
      "41 Train loss: 0.043260556\n",
      "42 Train loss: 0.02944677\n",
      "43 Train loss: 0.05494993\n",
      "44 Train loss: 0.039922547\n",
      "45 Train loss: 0.051651634\n",
      "45 Test accuracy 0.9726\n",
      "46 Train loss: 0.043890547\n",
      "47 Train loss: 0.06915612\n",
      "48 Train loss: 0.05046885\n",
      "49 Train loss: 0.024549404\n",
      "50 Train loss: 0.03918027\n",
      "50 Test accuracy 0.9738\n",
      "51 Train loss: 0.057676256\n",
      "52 Train loss: 0.05272555\n",
      "53 Train loss: 0.03333446\n",
      "54 Train loss: 0.024490153\n",
      "55 Train loss: 0.039820354\n",
      "55 Test accuracy 0.9756\n",
      "56 Train loss: 0.054805465\n",
      "57 Train loss: 0.030655699\n",
      "58 Train loss: 0.04008755\n",
      "59 Train loss: 0.031412754\n",
      "60 Train loss: 0.04563334\n",
      "60 Test accuracy 0.9773\n",
      "61 Train loss: 0.04114746\n",
      "62 Train loss: 0.031952746\n",
      "63 Train loss: 0.031598046\n",
      "64 Train loss: 0.038807347\n",
      "65 Train loss: 0.041743904\n",
      "65 Test accuracy 0.9756\n",
      "66 Train loss: 0.031175995\n",
      "67 Train loss: 0.041053806\n",
      "68 Train loss: 0.018462965\n",
      "69 Train loss: 0.034604102\n",
      "70 Train loss: 0.008461965\n",
      "70 Test accuracy 0.9741\n",
      "71 Train loss: 0.010124613\n",
      "72 Train loss: 0.03606652\n",
      "73 Train loss: 0.026071927\n",
      "74 Train loss: 0.032291736\n",
      "75 Train loss: 0.04074055\n",
      "75 Test accuracy 0.978\n",
      "76 Train loss: 0.030279888\n",
      "77 Train loss: 0.0207566\n",
      "78 Train loss: 0.012694435\n",
      "79 Train loss: 0.013862515\n",
      "80 Train loss: 0.016103048\n",
      "80 Test accuracy 0.9782\n",
      "81 Train loss: 0.01367185\n",
      "82 Train loss: 0.017456725\n",
      "83 Train loss: 0.017235382\n",
      "84 Train loss: 0.03419717\n",
      "85 Train loss: 0.010985473\n",
      "85 Test accuracy 0.9779\n",
      "86 Train loss: 0.008451899\n",
      "87 Train loss: 0.02402382\n",
      "88 Train loss: 0.019891111\n",
      "89 Train loss: 0.03477874\n",
      "90 Train loss: 0.027837394\n",
      "90 Test accuracy 0.9771\n",
      "91 Train loss: 0.028441226\n",
      "92 Train loss: 0.018650029\n",
      "93 Train loss: 0.021418009\n",
      "94 Train loss: 0.011922933\n",
      "95 Train loss: 0.028555369\n",
      "95 Test accuracy 0.9767\n",
      "96 Train loss: 0.030030675\n",
      "97 Train loss: 0.0323244\n",
      "98 Train loss: 0.011986656\n",
      "99 Train loss: 0.030822968\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)\n",
    "            loss_val, _ = sess.run([loss, training_op], feed_dict={X: X_batch, y: y_batch})\n",
    "        print(epoch, \"Train loss:\", loss_val)\n",
    "        if epoch % 5 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "            print(epoch, \"Test accuracy\", acc_test)\n",
    "    save_path = saver.save(sess,'./my_digit_comparison_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime('%Y%m%d%H%H%S')\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, \"DNN\")\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dnn/DNN_Ahidden5/Elu:0' shape=(?, 100) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name('dnn/DNN_Ahidden5/Elu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
