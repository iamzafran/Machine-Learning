{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_moons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=10000, noise=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m, n = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.constant(X_train_scaled, dtype=tf.float32, name='x')\n",
    "y = tf.constant(y_train.reshape(-1,1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), name='theta')\n",
    "t = tf.matmul(x, theta, name='t')\n",
    "y_pred = tf.sigmoid(t)\n",
    "epsilon = 1e-7 \n",
    "loss = tf.losses.log_loss(y, y_pred)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "training_op = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 Cost 0.91843253\n",
      "Epoch  100 Cost 0.6895441\n",
      "Epoch  200 Cost 0.56927073\n",
      "Epoch  300 Cost 0.5035454\n",
      "Epoch  400 Cost 0.46458122\n",
      "Epoch  500 Cost 0.4397073\n",
      "Epoch  600 Cost 0.42287698\n",
      "Epoch  700 Cost 0.4109681\n",
      "Epoch  800 Cost 0.4022435\n",
      "Epoch  900 Cost 0.3956738\n",
      "Epoch  1000 Cost 0.39061612\n",
      "Epoch  1100 Cost 0.3866514\n",
      "Epoch  1200 Cost 0.38349634\n",
      "Epoch  1300 Cost 0.38095367\n",
      "Epoch  1400 Cost 0.37888235\n",
      "Epoch  1500 Cost 0.37717932\n",
      "Epoch  1600 Cost 0.3757678\n",
      "Epoch  1700 Cost 0.37458968\n",
      "Epoch  1800 Cost 0.3736003\n",
      "Epoch  1900 Cost 0.37276483\n",
      "Epoch  2000 Cost 0.37205598\n",
      "Epoch  2100 Cost 0.37145194\n",
      "Epoch  2200 Cost 0.3709351\n",
      "Epoch  2300 Cost 0.37049147\n",
      "Epoch  2400 Cost 0.37010938\n",
      "Epoch  2500 Cost 0.36977938\n",
      "Epoch  2600 Cost 0.36949363\n",
      "Epoch  2700 Cost 0.36924556\n",
      "Epoch  2800 Cost 0.36902976\n",
      "Epoch  2900 Cost 0.36884168\n",
      "Epoch  3000 Cost 0.3686774\n",
      "Epoch  3100 Cost 0.36853373\n",
      "Epoch  3200 Cost 0.36840782\n",
      "Epoch  3300 Cost 0.36829734\n",
      "Epoch  3400 Cost 0.36820033\n",
      "Epoch  3500 Cost 0.368115\n",
      "Epoch  3600 Cost 0.36803988\n",
      "Epoch  3700 Cost 0.3679736\n",
      "Epoch  3800 Cost 0.3679151\n",
      "Epoch  3900 Cost 0.36786348\n",
      "Epoch  4000 Cost 0.36781782\n",
      "Epoch  4100 Cost 0.36777744\n",
      "Epoch  4200 Cost 0.36774167\n",
      "Epoch  4300 Cost 0.36771002\n",
      "Epoch  4400 Cost 0.36768195\n",
      "Epoch  4500 Cost 0.36765704\n",
      "Epoch  4600 Cost 0.36763492\n",
      "Epoch  4700 Cost 0.36761528\n",
      "Epoch  4800 Cost 0.36759782\n",
      "Epoch  4900 Cost 0.36758235\n",
      "Epoch  5000 Cost 0.36756852\n",
      "Epoch  5100 Cost 0.36755627\n",
      "Epoch  5200 Cost 0.36754537\n",
      "Epoch  5300 Cost 0.36753565\n",
      "Epoch  5400 Cost 0.36752704\n",
      "Epoch  5500 Cost 0.36751926\n",
      "Epoch  5600 Cost 0.3675124\n",
      "Epoch  5700 Cost 0.36750627\n",
      "Epoch  5800 Cost 0.3675008\n",
      "Epoch  5900 Cost 0.36749595\n",
      "Epoch  6000 Cost 0.3674916\n",
      "Epoch  6100 Cost 0.36748776\n",
      "Epoch  6200 Cost 0.36748424\n",
      "Epoch  6300 Cost 0.36748117\n",
      "Epoch  6400 Cost 0.36747843\n",
      "Epoch  6500 Cost 0.367476\n",
      "Epoch  6600 Cost 0.36747375\n",
      "Epoch  6700 Cost 0.36747178\n",
      "Epoch  6800 Cost 0.36747003\n",
      "Epoch  6900 Cost 0.36746848\n",
      "Epoch  7000 Cost 0.36746708\n",
      "Epoch  7100 Cost 0.3674658\n",
      "Epoch  7200 Cost 0.36746472\n",
      "Epoch  7300 Cost 0.3674637\n",
      "Epoch  7400 Cost 0.3674628\n",
      "Epoch  7500 Cost 0.367462\n",
      "Epoch  7600 Cost 0.3674613\n",
      "Epoch  7700 Cost 0.36746064\n",
      "Epoch  7800 Cost 0.3674601\n",
      "Epoch  7900 Cost 0.36745954\n",
      "Epoch  8000 Cost 0.36745912\n",
      "Epoch  8100 Cost 0.3674587\n",
      "Epoch  8200 Cost 0.36745837\n",
      "Epoch  8300 Cost 0.36745802\n",
      "Epoch  8400 Cost 0.36745772\n",
      "Epoch  8500 Cost 0.36745748\n",
      "Epoch  8600 Cost 0.36745724\n",
      "Epoch  8700 Cost 0.36745703\n",
      "Epoch  8800 Cost 0.36745685\n",
      "Epoch  8900 Cost 0.36745667\n",
      "Epoch  9000 Cost 0.36745653\n",
      "Epoch  9100 Cost 0.36745638\n",
      "Epoch  9200 Cost 0.36745626\n",
      "Epoch  9300 Cost 0.3674561\n",
      "Epoch  9400 Cost 0.36745605\n",
      "Epoch  9500 Cost 0.36745596\n",
      "Epoch  9600 Cost 0.3674559\n",
      "Epoch  9700 Cost 0.3674558\n",
      "Epoch  9800 Cost 0.36745575\n",
      "Epoch  9900 Cost 0.3674557\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 10000\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch ', epoch, 'Cost', loss.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.2803108],\n",
       "       [-1.8139111]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m/batch_size))\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
    "    X_batch = X_train_scaled[indices] # not shown\n",
    "    y_batch = y_train[indices] # not shown\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_mini = tf.placeholder(tf.float32, shape=(None, n), name='x_mini')\n",
    "y_mini = tf.placeholder(tf.float32, shape=(None, 1), name='y_mini')\n",
    "theta = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), name='theta')\n",
    "t = tf.matmul(x, theta, name='t')\n",
    "y_pred = tf.sigmoid(t)\n",
    "epsilon = 1e-7 \n",
    "loss = tf.losses.log_loss(y, y_pred)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            y_batch = y_batch.reshape(-1, 1)\n",
    "            sess.run(training_op, feed_dict={x_mini: X_batch, y_mini:y_batch})\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
